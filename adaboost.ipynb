{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-08T14:34:35.869526Z","iopub.execute_input":"2023-03-08T14:34:35.870016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Resources: \n* https://www.analyticsvidhya.com/blog/2021/09/adaboost-algorithm-a-complete-guide-for-beginners/\n* sklearn documentation\n* Multi class adaboost Ji Zhu\n* AdaBoost-CNN Aboozar","metadata":{}},{"cell_type":"markdown","source":"### Imports","metadata":{}},{"cell_type":"code","source":"!python --version","metadata":{"execution":{"iopub.status.busy":"2023-03-08T13:44:21.851262Z","iopub.execute_input":"2023-03-08T13:44:21.851648Z","iopub.status.idle":"2023-03-08T13:44:22.790770Z","shell.execute_reply.started":"2023-03-08T13:44:21.851613Z","shell.execute_reply":"2023-03-08T13:44:22.789644Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nPython 3.7.12\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install dlib","metadata":{"execution":{"iopub.status.busy":"2023-03-08T13:45:53.531999Z","iopub.execute_input":"2023-03-08T13:45:53.532839Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nCollecting dlib\n  Downloading dlib-19.24.0.tar.gz (3.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: dlib\n  Building wheel for dlib (setup.py) ... \u001b[?25l\\","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nimport numpy as np\nimport cv2\n\nimport PIL.Image as Image\nimport os\n\nimport matplotlib.pylab as plt\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom tensorflow.keras.optimizers.experimental import RMSprop, Adam\nimport gc\nimport random\nimport math\nimport keras.backend as K\nfrom sklearn.model_selection import train_test_split\n\n#import libraries\nimport keras\nfrom keras.models import Sequential , Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.layers import Input, Add, Activation, ZeroPadding2D, BatchNormalization, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D , Dense, Conv2D, MaxPool2D , Flatten , concatenate ,DepthwiseConv2D, GlobalAveragePooling2D , ReLU\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\n#import dlib\n\ntf.keras.utils.set_random_seed(42)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T14:51:45.490010Z","iopub.execute_input":"2023-03-08T14:51:45.490406Z","iopub.status.idle":"2023-03-08T14:51:45.502603Z","shell.execute_reply.started":"2023-03-08T14:51:45.490374Z","shell.execute_reply":"2023-03-08T14:51:45.501501Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"tf. __version__","metadata":{"execution":{"iopub.status.busy":"2023-03-08T11:18:33.588950Z","iopub.execute_input":"2023-03-08T11:18:33.589326Z","iopub.status.idle":"2023-03-08T11:18:33.596252Z","shell.execute_reply.started":"2023-03-08T11:18:33.589296Z","shell.execute_reply":"2023-03-08T11:18:33.595130Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'2.9.2'"},"metadata":{}}]},{"cell_type":"code","source":"def ReSize(image, size):\n    resizedimg=cv2.resize(image,(size,size))\n    return resizedimg \n\ndef normalize(resimg):\n    img=cv2.cvtColor(resimg,cv2.COLOR_BGR2RGB)\n    img_normalized = cv2.normalize(img, None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n    img1=cv2.cvtColor(img_normalized,cv2.COLOR_BGR2RGB)\n    return img1    \n\ndef gray(normimg):\n    img=cv2.cvtColor(normimg, cv2.COLOR_BGR2GRAY)\n    grey=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    return grey\n\ndef Brightnessandcontrast(normimg):\n    Bright = 20\n    Contrast = 1\n    img=cv2.cvtColor(normimg,cv2.COLOR_BGR2RGB)\n    adjusted = cv2.convertScaleAbs(img, alpha=Contrast, beta=Bright)\n    rgbadjusted=cv2.cvtColor(adjusted,cv2.COLOR_BGR2RGB)\n    return rgbadjusted\n\ndef mean_noise_reduction(normimg):\n    img=cv2.cvtColor(normimg,cv2.COLOR_BGR2RGB)\n    filteredimg = cv2.fastNlMeansDenoisingColored(img,None,10,10,7,21)\n    rgbfilteredimg=cv2.cvtColor(filteredimg,cv2.COLOR_BGR2RGB)\n    return rgbfilteredimg\n\ndef three_noise_reduction(normimg):\n    img=cv2.cvtColor(normimg,cv2.COLOR_BGR2RGB)\n    filteredimg =cv2.GaussianBlur(img,(5,5),0)\n    #filteredimg=cv2.blur(img,(5,5))\n    #filteredimg=cv2.medianBlur(img,5)\n    rgbfilteredimg=cv2.cvtColor(filteredimg,cv2.COLOR_BGR2RGB)\n    return rgbfilteredimg\n\ndef face_detection(samdata):\n    \n    detector = dlib.get_frontal_face_detector()\n    greyimg=cv2.cvtColor(samdata, cv2.COLOR_BGR2GRAY)\n    detectedimg = detector(greyimg)  \n    if len(detectedimg) == 0:\n        samdata\n    else:\n        for face in detectedimg:\n            x1 = face.left()\n            y1 = face.top()\n            x2 = face.right()\n            y2 = face.bottom()\n\n            img=cv2.rectangle(samdata, (x1, y1), (x2, y2), (0, 0, 0), 2)\n            img_height, img_width, c = img.shape\n            cropped = img[max(0, face.top()): min(face.bottom(), img_height),max(0, face.left()): min(face.right(), img_width)]\n\n    return cropped","metadata":{"execution":{"iopub.status.busy":"2023-03-08T16:10:58.007776Z","iopub.execute_input":"2023-03-08T16:10:58.008230Z","iopub.status.idle":"2023-03-08T16:10:58.026141Z","shell.execute_reply.started":"2023-03-08T16:10:58.008192Z","shell.execute_reply":"2023-03-08T16:10:58.024800Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"### Read Data","metadata":{}},{"cell_type":"code","source":"def read_data(list, photo_size):  \n    data = []\n    for i in range(len(list)):\n        for filename in os.listdir(list[i]):\n            img  = cv2.imread(list[i] + filename)\n            #img = face_detection(img)\n            #img = gray(img)\n            #img = Brightnessandcontrast(img)\n            #img = mean_noise_reduction(img)\n            #img = three_noise_reduction(img)\n            img = ReSize(img, photo_size)\n            img = normalize(img)\n            data.append([img, [i%2, abs(i%2 - 1)] ])\n        \n    \n    random.shuffle(data)\n    x = []\n    y = []\n    for i in range(len(data)):\n        x.append(data[i][0])\n        y.append(data[i][1])\n    \n    x = np.array(x)\n    y = np.array(y\n    return data","metadata":{"execution":{"iopub.status.busy":"2023-03-08T14:55:00.937580Z","iopub.execute_input":"2023-03-08T14:55:00.938906Z","iopub.status.idle":"2023-03-08T14:55:00.946806Z","shell.execute_reply.started":"2023-03-08T14:55:00.938851Z","shell.execute_reply":"2023-03-08T14:55:00.945542Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Data split","metadata":{}},{"cell_type":"code","source":"ta = \"/kaggle/input/autistic-children-facial-data-set/train/autistic/\"\ntn = \"/kaggle/input/autistic-children-facial-data-set/train/non_autistic/\"\ntesta = \"/kaggle/input/autistic-children-facial-data-set/test/autistic/\"\ntestn = \"/kaggle/input/autistic-children-facial-data-set/test/non_autistic/\"\nva = \"/kaggle/input/autistic-children-facial-data-set/valid/autistic/\"\nvn = \"/kaggle/input/autistic-children-facial-data-set/valid/non_autistic/\"\n\nlis = [tn, ta , testn, testa, vn, va]\n\n\nx, y = read_data(lis , 224)\nprint(x.shape)\nprint(y.shape)\n\ndel ta , tn , testa, testn, va, vn, lis\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T14:55:33.797358Z","iopub.execute_input":"2023-03-08T14:55:33.798572Z","iopub.status.idle":"2023-03-08T14:55:40.121874Z","shell.execute_reply.started":"2023-03-08T14:55:33.798525Z","shell.execute_reply":"2023-03-08T14:55:40.120837Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"y.sum(axis = 0)","metadata":{"execution":{"iopub.status.busy":"2023-03-07T16:57:27.486344Z","iopub.execute_input":"2023-03-07T16:57:27.487029Z","iopub.status.idle":"2023-03-07T16:57:27.494439Z","shell.execute_reply.started":"2023-03-07T16:57:27.486991Z","shell.execute_reply":"2023-03-07T16:57:27.493297Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"array([1468, 1468])"},"metadata":{}}]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 0.85, test_size = 0.15, stratify = y)\nx_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, train_size = 0.9, test_size = 0.1, stratify = y_train)\ndel x, y\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-03-07T16:57:27.496203Z","iopub.execute_input":"2023-03-07T16:57:27.496590Z","iopub.status.idle":"2023-03-07T16:57:31.197638Z","shell.execute_reply.started":"2023-03-07T16:57:27.496551Z","shell.execute_reply":"2023-03-07T16:57:31.195927Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"46"},"metadata":{}}]},{"cell_type":"code","source":"print(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)\nprint(x_valid.shape)\nprint(y_valid.shape)","metadata":{"execution":{"iopub.status.busy":"2023-03-07T16:57:31.200711Z","iopub.execute_input":"2023-03-07T16:57:31.201012Z","iopub.status.idle":"2023-03-07T16:57:31.208332Z","shell.execute_reply.started":"2023-03-07T16:57:31.200983Z","shell.execute_reply":"2023-03-07T16:57:31.207013Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"(2245, 224, 224, 3)\n(2245, 2)\n(441, 224, 224, 3)\n(441, 2)\n(250, 224, 224, 3)\n(250, 2)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Xception","metadata":{}},{"cell_type":"code","source":"def make_model():\n    xception = tf.keras.applications.Xception(input_shape=(224, 224,3), include_top=False, weights=\"imagenet\" )\n    \n    model = tf.keras.models.Sequential([\n    xception,\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(128, \"relu\"),\n    tf.keras.layers.Dense(64, \"relu\"),\n    tf.keras.layers.Dense(2, \"softmax\")\n    ])\n      \n    return model\n","metadata":{"execution":{"iopub.status.busy":"2023-03-07T16:33:56.952248Z","iopub.execute_input":"2023-03-07T16:33:56.952619Z","iopub.status.idle":"2023-03-07T16:33:56.960123Z","shell.execute_reply.started":"2023-03-07T16:33:56.952580Z","shell.execute_reply":"2023-03-07T16:33:56.959091Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"### MoibleNet","metadata":{}},{"cell_type":"code","source":"def depth_block(x, strides):\n    x = DepthwiseConv2D(3,strides=strides,padding='same',  use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    return x\ndef single_conv_block(x,filters):\n    x = Conv2D(filters, 1,use_bias=False)(x)\n    x= BatchNormalization()(x)\n    x = ReLU()(x)\n    return x\ndef combo_layer(x,filters,strides):\n    x = depth_block(x,strides)\n    x = single_conv_block(x, filters)\n    return x\ndef MobileNet(input_shape=(224,224,3),n_classes = 2):\n    input =layers.Input( input_shape)\n    x = Conv2D(32,3,strides=(2,2),padding = 'same', use_bias=False) (input)\n    x =  BatchNormalization()(x)\n    x = ReLU()(x)\n    x = combo_layer(x,64, strides=(1,1))\n    x = combo_layer(x,128,strides=(2,2))\n    x = combo_layer(x,128,strides=(1,1))\n    x = combo_layer(x,256,strides=(2,2))\n    x = combo_layer(x,256,strides=(1,1))\n    x = combo_layer(x,512,strides=(2,2))\n    for _ in range(5):\n        x = combo_layer(x,512,strides=(1,1))\n    x = combo_layer(x,1024,strides=(2,2))\n    x = combo_layer(x,1024,strides=(1,1))\n    x = GlobalAveragePooling2D()(x)\n    output = Dense(n_classes,activation='softmax')(x)\n    model = Model(input, output)\n    return model","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SAMME Algorithm","metadata":{}},{"cell_type":"code","source":"def samme_evalution(x,y,n_e, estimators_alphas, estimators):\n    predicted = []\n    for i in range(n_e):\n        predicted.append(estimators[i].predict(x))\n        gc.collect()\n    _m5ra = []   \n    for i in range(n_e):\n        _m5ra.append([estimators_alphas[i] * j for j in predicted[i].round()])\n    _m5ra = np.array(_m5ra).sum(axis = 0)\n\n    acc = 0\n    for i in range(len(x)):\n       if (np.argmax(_m5ra[i])) == (np.argmax(y[i])):\n            acc += 1 \n    return acc / y.shape[0]","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"estimators = []  # list of models\nestimators_weights = [] # list of CNN weights of each model\nestimators_alphas = [] # \nsample_weights = [] # list of sample weights of each model\nn_e = 6 # number of models\ngc.collect()\n\nfor i in range(0, n_e):\n    gc.collect()\n    # models after base\n    if i > 0 :\n        estimator = make_model()\n        gc.collect()\n        estimator.set_weights(estimators_weights[i-1])\n        gc.collect()\n        estimator.compile(optimizer=\"RMSprop\",loss=tf.keras.losses.BinaryCrossentropy(),metrics=['acc'])\n        gc.collect()\n        sample_weight = sample_weights[i-1]\n        gc.collect()\n    # base model\n    else:\n        estimator = make_model()\n        gc.collect()\n        estimator.compile(optimizer=\"RMSprop\",loss=tf.keras.losses.BinaryCrossentropy(),metrics=['acc'])\n        gc.collect()\n        sample_weight = np.ones( x_train.shape[0] ) / x_train.shape[0]\n        gc.collect()\n    \n        \n    print(f\"Estimator no. {i+1} \\n\\n\")\n    gc.collect()\n    gc.collect()\n    \n    # base model and others could have different epochs\n    if i > 0:\n        estimator.fit(x_train, y_train, sample_weight = sample_weight, validation_data = [x_valid , y_valid], epochs = 1, batch_size = 32)\n    else:\n        estimator.fit(x_train, y_train, sample_weight = sample_weight, validation_data = [x_valid , y_valid], epochs = 1, batch_size = 32)\n    gc.collect()\n    gc.collect()\n    \n    # simple evaluation for each model\n    print(\"\\n\\n\")\n    print(f\"Train Acc: {estimator.evaluate(x_train, y_train)}\\n\\n\")\n    gc.collect()\n    gc.collect()\n    print(f\"Test Acc: {estimator.evaluate(x_test, y_test)}\\n\\n\")\n    gc.collect()\n    gc.collect()\n    print(f\"Valid Acc: {estimator.evaluate(x_valid, y_valid)}\\n\\n\")\n    gc.collect()\n    gc.collect()\n    \n    \n    # Step 2: Calculate the err equation\n    #print(\"start step 2\")\n    predicted = (estimator.predict(x_train)).round()\n    gc.collect()\n    gc.collect()\n    \n    # 1 if the model classifiy it wrong, 0 then it is calssified it right\n    incorrect = np.array([1 if i.all() == True else 0 for i in predicted != y_train ])\n    del predicted\n    gc.collect()\n    \n    error = np.dot(incorrect, sample_weight) / np.sum(sample_weight)\n    #print(f\"err = {error}\\n\\n\")\n    gc.collect()\n\n    ############ we need to change this condition  ###############\n    if error >= 1 - 1 / 2 and i > 0:\n        print(\"stoped boosting\")\n        break\n    \n    #print(\"start step 3\")\n    # step 3: caluclate the alpha\n    lr = K.eval(estimator.optimizer.lr)\n    alpha = lr*(math.log((1-error)/error)) + math.log(2-1)\n    del error, lr\n    gc.collect()\n    \n    #print(\"start step 4\")\n    # step 4: update the weights\n    sample_weight *= np.exp(alpha * incorrect) \n    gc.collect()\n    sample_weight /= sample_weight.sum()\n    \n    # appending and cleaning before repeating\n    estimators_alphas.append(alpha)\n    del alpha , incorrect\n    gc.collect()\n    \n    estimators.append(estimator)\n    gc.collect()\n    \n    estimators_weights.append(estimator.get_weights())\n    del estimator\n    gc.collect()\n    \n    sample_weights.append(sample_weight)\n    del sample_weight\n    gc.collect()\n    \n    #print(\"finish \\n\")\n\ndel estimators_weights\ngc.collect()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\" Train Acc: {samme_evalution(x_train,y_train,n_e, estimators_alphas, estimators)}\")\nprint(f\" Test Acc: {samme_evalution(x_test,y_test,n_e, estimators_alphas, estimators)}\")\nprint(f\" Validation Acc: {samme_evalution(x_valid,y_valid,n_e, estimators_alphas, estimators)}\")","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Notes\n","metadata":{}},{"cell_type":"markdown","source":"# SAMME.R","metadata":{}},{"cell_type":"code","source":"# Step 3: Calculate h\ndef Hk(predicted, k = 2):\n    predicted = np.array(predicted)\n    predicted[predicted < np.finfo(predicted.dtype).eps] = np.finfo(predicted.dtype).eps\n    log_predict = np.log(predicted)\n    h = (k-1) * (log_predict - 1/k * log_predict.sum())\n    \n    return h\n\ndef evaluate(x, y, estimators, n_e, hk = None, k = 2):\n    if hk == None:\n        hk = []\n        for i in range(0,n_e):\n            hk.append(estimators[i].predict(x))\n            gc.collect()\n\n        hk = np.array(hk)\n        hk[hk < np.finfo(hk.dtype).eps] = np.finfo(hk.dtype).eps\n        gc.collect()\n        log_prop = np.log(hk)\n        gc.collect()\n        intermediate = (k-1) * (log_prop - 1/k * log_prop.sum())\n        gc.collect()\n        intermediate = intermediate.sum(axis = 0)\n    else:\n        intermediate = np.array(hk).sum(axis = 0)\n    acc = 0\n    for i in range(len(y)):\n       if (np.argmax(intermediate[i])) == (np.argmax(y[i])):\n            acc += 1 \n    print(f\"Accuracy : {acc/y.shape[0]}\")\n    return acc/y.shape[0]","metadata":{"execution":{"iopub.status.busy":"2023-03-07T16:33:29.360329Z","iopub.execute_input":"2023-03-07T16:33:29.360701Z","iopub.status.idle":"2023-03-07T16:33:29.371051Z","shell.execute_reply.started":"2023-03-07T16:33:29.360664Z","shell.execute_reply":"2023-03-07T16:33:29.370028Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"gc.collect()\ntf.random.set_seed(42)\ngc.collect()\n\nestimators = [] # list of models\nestimators_weights = [] # list of CNN weights of each model\nsample_weights = [] # list of sample weights of each model\n#H = [] # list of h of each model\n\nestimators_pred = []\n\ny_labels = [ i[0] for i in y_train]\ny_coding = np.array([1 if i == 1 else -1 for i in y_labels])\n\nn_e = 10\ngc.collect()\n\nfor i in range(0, n_e):\n    gc.collect()\n    # models after base\n    if i > 0 :\n        estimator = make_model() #MobileNet()\n        gc.collect()\n        estimator.set_weights(estimators_weights[i-1])\n        gc.collect()\n        estimator.compile(optimizer=\"adam\",loss=tf.keras.losses.BinaryCrossentropy(),metrics=['acc'])\n        gc.collect()\n        sample_weight = sample_weights[i-1]\n        gc.collect()\n    \n    # base model\n    else:\n        estimator = make_model() #MobileNet()\n        gc.collect()\n        estimator.compile(optimizer=\"RMSprop\",loss=tf.keras.losses.BinaryCrossentropy(),metrics=['acc'])\n        gc.collect()\n        sample_weight = np.ones(x_train.shape[0]) / x_train.shape[0]\n        gc.collect()\n    \n        \n    print(f\"Estimator no. {i+1} \\n\\n\")\n    gc.collect()\n    gc.collect()\n    \n    # base model and others could have different epochs\n    if i > 0:\n        estimator.fit(x_train, y_train, sample_weight=sample_weight, validation_data = [x_valid , y_valid], epochs = 1, batch_size = 32)\n    else:\n        estimator.fit(x_train, y_train, sample_weight=sample_weight, validation_data = [x_valid , y_valid], epochs = 7, batch_size = 8)\n    gc.collect()\n    gc.collect()\n    \n    # simple evaluation for each model\n    print(\"\\n\\n\")\n    print(f\"Train Acc: {estimator.evaluate(x_train, y_train)}\\n\\n\")\n    gc.collect()\n    gc.collect()\n    print(f\"Test Acc: {estimator.evaluate(x_test, y_test)}\\n\\n\")\n    gc.collect()\n    gc.collect()\n    print(f\"Valid Acc: {estimator.evaluate(x_valid, y_valid)}\\n\\n\")\n    gc.collect()\n    gc.collect()\n    \n    ############# first we need to calculate the alpha for early stopping ############\n    #################################################################################\n    ################### DONT, DONT, DONT FOOOOOORGEEEEEEET #########################\n    ################### DONT, DONT, DONT FOOOOOORGEEEEEEET #########################\n    ###############################################################################\n    \n    # Step 2: get class predicted prop\n    #print(\"start step 2\")\n    predicted = (estimator.predict(x_train, verbose=0))\n    gc.collect()\n    gc.collect()\n    \n    prop = np.array([predicted[i][0] for i in range(len(y_train))])\n    prop[prop < np.finfo(prop.dtype).eps] = np.finfo(prop.dtype).eps\n    gc.collect()\n    gc.collect()\n    \n    # Step 3: Calculate h\n    #predicted = np.array(predicted)\n    #H.append(Hk(predicted))\n    #del predicted\n    #gc.collect()\n    #gc.collect()\n    \n    #print(\"start step 4\")\n    # step 4: update the weights\n    lr =  1 #K.eval(estimator.optimizer.lr)\n    intermediate_value = np.exp(-lr * (((2 - 1) / 2) * (np.abs(y_coding)* np.log(prop))))\n    gc.collect()\n    sample_weight = sample_weight * intermediate_value\n    gc.collect()\n    sample_weight = sample_weight / sample_weight.sum()\n    del intermediate_value, prop, lr\n    gc.collect()\n    \n    # appending and cleaning before repeating\n    estimators.append(estimator)\n    gc.collect()\n    \n    estimators_weights.append(estimator.get_weights())\n    del estimator\n    gc.collect()\n    \n    sample_weights.append(sample_weight)\n    del sample_weight\n    gc.collect()\n    #print(\"finish \\n\")\n\ndel estimators_weights\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-03-07T20:31:03.992644Z","iopub.execute_input":"2023-03-07T20:31:03.993037Z","iopub.status.idle":"2023-03-07T20:48:23.858775Z","shell.execute_reply.started":"2023-03-07T20:31:03.993000Z","shell.execute_reply":"2023-03-07T20:48:23.857740Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"Estimator no. 1 \n\n\nEpoch 1/7\n281/281 [==============================] - 45s 129ms/step - loss: 3.0936e-04 - acc: 0.5024 - val_loss: 0.6575 - val_acc: 0.6800\nEpoch 2/7\n281/281 [==============================] - 35s 125ms/step - loss: 2.7073e-04 - acc: 0.6739 - val_loss: 1.1993 - val_acc: 0.7240\nEpoch 3/7\n281/281 [==============================] - 35s 125ms/step - loss: 2.1912e-04 - acc: 0.7817 - val_loss: 0.4499 - val_acc: 0.7960\nEpoch 4/7\n281/281 [==============================] - 35s 125ms/step - loss: 1.8204e-04 - acc: 0.8214 - val_loss: 0.4442 - val_acc: 0.8280\nEpoch 5/7\n281/281 [==============================] - 35s 125ms/step - loss: 1.5443e-04 - acc: 0.8588 - val_loss: 1.5483 - val_acc: 0.6880\nEpoch 6/7\n281/281 [==============================] - 35s 125ms/step - loss: 1.3206e-04 - acc: 0.8784 - val_loss: 1.1936 - val_acc: 0.7720\nEpoch 7/7\n281/281 [==============================] - 35s 125ms/step - loss: 1.0976e-04 - acc: 0.9078 - val_loss: 0.6550 - val_acc: 0.7800\n\n\n\n71/71 [==============================] - 6s 80ms/step - loss: 0.2506 - acc: 0.8717\nTrain Acc: [0.2505533993244171, 0.8717149496078491]\n\n\n14/14 [==============================] - 1s 79ms/step - loss: 0.5922 - acc: 0.7596\nTest Acc: [0.5921558737754822, 0.759637176990509]\n\n\n8/8 [==============================] - 1s 80ms/step - loss: 0.6550 - acc: 0.7800\nValid Acc: [0.6549989581108093, 0.7799999713897705]\n\n\nEstimator no. 2 \n\n\n71/71 [==============================] - 33s 396ms/step - loss: 8.6443e-07 - acc: 0.9465 - val_loss: 0.4996 - val_acc: 0.8200\n\n\n\n71/71 [==============================] - 6s 80ms/step - loss: 0.1416 - acc: 0.9403\nTrain Acc: [0.1415862888097763, 0.9403117895126343]\n\n\n14/14 [==============================] - 1s 79ms/step - loss: 0.4299 - acc: 0.8095\nTest Acc: [0.4298757016658783, 0.8095238208770752]\n\n\n8/8 [==============================] - 1s 78ms/step - loss: 0.4996 - acc: 0.8200\nValid Acc: [0.4996436834335327, 0.8199999928474426]\n\n\nEstimator no. 3 \n\n\n71/71 [==============================] - 33s 395ms/step - loss: 6.2023e-08 - acc: 0.9501 - val_loss: 0.4774 - val_acc: 0.8200\n\n\n\n71/71 [==============================] - 6s 80ms/step - loss: 0.1387 - acc: 0.9501\nTrain Acc: [0.13867604732513428, 0.9501113295555115]\n\n\n14/14 [==============================] - 1s 79ms/step - loss: 0.4156 - acc: 0.8141\nTest Acc: [0.4155918061733246, 0.8140589594841003]\n\n\n8/8 [==============================] - 1s 77ms/step - loss: 0.4774 - acc: 0.8200\nValid Acc: [0.4774128794670105, 0.8199999928474426]\n\n\nEstimator no. 4 \n\n\n71/71 [==============================] - 33s 398ms/step - loss: 3.1456e-08 - acc: 0.9501 - val_loss: 0.4712 - val_acc: 0.8280\n\n\n\n71/71 [==============================] - 6s 80ms/step - loss: 0.1401 - acc: 0.9501\nTrain Acc: [0.1401270627975464, 0.9501113295555115]\n\n\n14/14 [==============================] - 1s 79ms/step - loss: 0.4138 - acc: 0.8118\nTest Acc: [0.41375651955604553, 0.8117913603782654]\n\n\n8/8 [==============================] - 1s 78ms/step - loss: 0.4712 - acc: 0.8280\nValid Acc: [0.4711833894252777, 0.828000009059906]\n\n\nEstimator no. 5 \n\n\n71/71 [==============================] - 32s 395ms/step - loss: 2.1211e-08 - acc: 0.9510 - val_loss: 0.4701 - val_acc: 0.8280\n\n\n\n71/71 [==============================] - 6s 79ms/step - loss: 0.1415 - acc: 0.9506\nTrain Acc: [0.14150764048099518, 0.9505568146705627]\n\n\n14/14 [==============================] - 1s 82ms/step - loss: 0.4149 - acc: 0.8095\nTest Acc: [0.41491708159446716, 0.8095238208770752]\n\n\n8/8 [==============================] - 1s 77ms/step - loss: 0.4701 - acc: 0.8280\nValid Acc: [0.47011667490005493, 0.828000009059906]\n\n\nEstimator no. 6 \n\n\n71/71 [==============================] - 32s 395ms/step - loss: 1.5978e-08 - acc: 0.9510 - val_loss: 0.4709 - val_acc: 0.8240\n\n\n\n71/71 [==============================] - 6s 79ms/step - loss: 0.1424 - acc: 0.9510\nTrain Acc: [0.142411008477211, 0.9510022401809692]\n\n\n14/14 [==============================] - 1s 79ms/step - loss: 0.4167 - acc: 0.8095\nTest Acc: [0.4167413115501404, 0.8095238208770752]\n\n\n8/8 [==============================] - 1s 78ms/step - loss: 0.4709 - acc: 0.8240\nValid Acc: [0.470906138420105, 0.8240000009536743]\n\n\nEstimator no. 7 \n\n\n71/71 [==============================] - 32s 395ms/step - loss: 1.2793e-08 - acc: 0.9510 - val_loss: 0.4724 - val_acc: 0.8240\n\n\n\n71/71 [==============================] - 6s 79ms/step - loss: 0.1430 - acc: 0.9514\nTrain Acc: [0.1429872363805771, 0.9514476656913757]\n\n\n14/14 [==============================] - 1s 80ms/step - loss: 0.4186 - acc: 0.8095\nTest Acc: [0.41864079236984253, 0.8095238208770752]\n\n\n8/8 [==============================] - 1s 77ms/step - loss: 0.4724 - acc: 0.8240\nValid Acc: [0.4724142253398895, 0.8240000009536743]\n\n\nEstimator no. 8 \n\n\n71/71 [==============================] - 32s 397ms/step - loss: 1.0644e-08 - acc: 0.9514 - val_loss: 0.4742 - val_acc: 0.8240\n\n\n\n71/71 [==============================] - 6s 79ms/step - loss: 0.1434 - acc: 0.9514\nTrain Acc: [0.1433694064617157, 0.9514476656913757]\n\n\n14/14 [==============================] - 1s 78ms/step - loss: 0.4205 - acc: 0.8095\nTest Acc: [0.4204867482185364, 0.8095238208770752]\n\n\n8/8 [==============================] - 1s 78ms/step - loss: 0.4742 - acc: 0.8240\nValid Acc: [0.474159836769104, 0.8240000009536743]\n\n\nEstimator no. 9 \n\n\n71/71 [==============================] - 32s 395ms/step - loss: 9.0958e-09 - acc: 0.9519 - val_loss: 0.4759 - val_acc: 0.8280\n\n\n\n71/71 [==============================] - 6s 80ms/step - loss: 0.1436 - acc: 0.9514\nTrain Acc: [0.14364473521709442, 0.9514476656913757]\n\n\n14/14 [==============================] - 1s 79ms/step - loss: 0.4222 - acc: 0.8095\nTest Acc: [0.4222051799297333, 0.8095238208770752]\n\n\n8/8 [==============================] - 1s 80ms/step - loss: 0.4759 - acc: 0.8280\nValid Acc: [0.47591039538383484, 0.828000009059906]\n\n\nEstimator no. 10 \n\n\n71/71 [==============================] - 32s 395ms/step - loss: 7.9276e-09 - acc: 0.9510 - val_loss: 0.4776 - val_acc: 0.8280\n\n\n\n71/71 [==============================] - 6s 79ms/step - loss: 0.1439 - acc: 0.9514\nTrain Acc: [0.1438625305891037, 0.9514476656913757]\n\n\n14/14 [==============================] - 1s 79ms/step - loss: 0.4238 - acc: 0.8073\nTest Acc: [0.42379313707351685, 0.8072562217712402]\n\n\n8/8 [==============================] - 1s 78ms/step - loss: 0.4776 - acc: 0.8280\nValid Acc: [0.4776000380516052, 0.828000009059906]\n\n\n","output_type":"stream"},{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"print(f\" Train Acc: {evaluate(x_train, y_train, estimators, n_e, k = 2)}\")\nprint(f\" Test Acc: {evaluate(x_test, y_test, estimators, n_e, k = 2)}\")\nprint(f\" Validation Acc: {evaluate(x_valid, y_valid, estimators, n_e, k = 2)}\")","metadata":{"execution":{"iopub.status.busy":"2023-03-07T20:48:23.862046Z","iopub.execute_input":"2023-03-07T20:48:23.863033Z","iopub.status.idle":"2023-03-07T20:51:03.090359Z","shell.execute_reply.started":"2023-03-07T20:48:23.862993Z","shell.execute_reply":"2023-03-07T20:51:03.089334Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"71/71 [==============================] - 5s 76ms/step\n71/71 [==============================] - 5s 77ms/step\n71/71 [==============================] - 5s 77ms/step\n71/71 [==============================] - 5s 77ms/step\n71/71 [==============================] - 5s 76ms/step\n71/71 [==============================] - 5s 76ms/step\n71/71 [==============================] - 5s 77ms/step\n71/71 [==============================] - 5s 76ms/step\n71/71 [==============================] - 5s 76ms/step\n71/71 [==============================] - 5s 76ms/step\nAccuracy : 0.9487750556792873\n Train Acc: 0.9487750556792873\n14/14 [==============================] - 1s 76ms/step\n14/14 [==============================] - 1s 74ms/step\n14/14 [==============================] - 1s 76ms/step\n14/14 [==============================] - 1s 77ms/step\n14/14 [==============================] - 1s 75ms/step\n14/14 [==============================] - 1s 74ms/step\n14/14 [==============================] - 1s 75ms/step\n14/14 [==============================] - 1s 76ms/step\n14/14 [==============================] - 1s 75ms/step\n14/14 [==============================] - 1s 77ms/step\nAccuracy : 0.8163265306122449\n Test Acc: 0.8163265306122449\n8/8 [==============================] - 1s 75ms/step\n8/8 [==============================] - 1s 74ms/step\n8/8 [==============================] - 1s 75ms/step\n8/8 [==============================] - 1s 74ms/step\n8/8 [==============================] - 1s 74ms/step\n8/8 [==============================] - 1s 75ms/step\n8/8 [==============================] - 1s 74ms/step\n8/8 [==============================] - 1s 75ms/step\n8/8 [==============================] - 1s 74ms/step\n8/8 [==============================] - 1s 74ms/step\nAccuracy : 0.824\n Validation Acc: 0.824\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Notes ","metadata":{}}]}